<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta http-equiv="Content-Language" content="en-us">
<link rel="stylesheet" href="style.css"> 
<title>CGO 2009 - Workshops</title>
<base target="_top">
</head>
<body>

<h1>CGO 2009 Workshops and Tutorials</h1>


<h2>Workshops</h2>
<table>
  <tr><td>EPHAM<td><a href="workshops.html#EPHAM">Workshop on Exploiting Parallelism using GPUs and other Hardware-Assisted Methods</a><font color="green">Program Finalized</font></tr>
  <tr><td>ODES<td><a href="http://www.imec.be/odes/">7th Workshop on Optimizations for DSP and Embedded
  <tr><td>OPEN64<td> <a href="http://www.capsl.udel.edu/conferences/open64/2009/">2nd Annual Workshop on Open64</a> </tr>
<!--
  <tr><td>STMCS<td> <a href="http://cag.csail.mit.edu/~rabbah/conferences/09/cgo/stmcs/">
      4th Workshop on Software Tools for MultiCore Systems</a></tr>
-->
  <tr><td><b>WISH</b><td> <a href="workshops.html#WISH">Workshop on Infrastructures for Software/Hardware co-design</a>
      <font color="green">Program finalized</font></tr>
 <tr><td>STMCS<td> <i>canceled</i></tr>
</table>


<h2>Tutorials</h2>
<table>
  <tr><td>SSA-RA<td> <a href="workshops.html#SSA">Tutorial on SSA-based Register Allocation</a></tr>
  <tr><td>STM<td> <i>canceled</i></tr>
  <tr><td>TBB<td> <i>canceled</i></tr>
</table>


<h2>Preliminary Schedule</h2>
<b>Sunday, 22 March 2009</b><br>
<p>
<table border="1">
  <tr><td>7:30am - 5:30pm<td>Registration - registration desk
  <tr><td>7:45am - 8:30am<td>Breakfast
  <tr><td>8:30am - 10:30am<td>Morning Session 1
  <tr><td>10:30am - 11:00am<td>Break
  <tr><td>11:00am - 12:30pm<td> Morning Session 2
  <tr><td>12:30pm - 1:30pm<td>Lunch
  <tr><td>1:30pm - 3:00pm<td>Afternoon Session 1
  <tr><td>3:00pm - 3:30pm<td>Break
  <tr><td>3:30pm - 5:30pm<td>Afternoon Session 2
</table>
<h2>Rooms</h2>
<table border="1" cellspacing="0" cellpadding="3">
  <tr><td>          <th>Room A<th>Room B<th>Room E<th>Room F</tr>
  <tr><td>Morning   <td>ODES  <td>Open64<td>EPHAM <td>SSA-RA</tr>
  <tr><td>Afternoon <td>ODES  <td>Open64<td>WISH  <td>   </tr>
</table>

<h2>Details</h2>

<h3>ODES - 7th Workshop on Optimizations for DSP and Embedded Systems</h3>


Program now <a href="http://www.imec.be/odes/odes-7_program.html">finalized</a>! <p>

Optimizations are crucial to meet the performance, power and cost
  requirements that DSP and embedded systems have. The aim of the ODES
  workshop is to give the opportunity to researchers and practitioners
  working on this, to share their findings and get feedback. We think
  interacting with the community is crucial to do relevant research,
and
  therefore ODES tries to maximize the interaction by  carefully
selecting
  the program committee members that review the submissions and at the
  workshop itself, reserving enough time for discussion.
<p>

  Topics of interest include, but are not limited to:
<p>
<ul>
  <li>   Algorithmic transformations and code/software optimization
  <li>   Hardware and software optimizations for low-power consumption and/or code density
  <li>   Coprocessor and hardware accelerators
  <li>   Compiler techniques and code generation for media processing
  <li>   Optimization techniques for algorithms and systems for video compression, pre and post processing
  <li>   Frameworks for profiling and scheduling tasks (multiple/concurrent) on various hardware resources (single-core + hardware accelerators, dual-core, system-on-a-chip, etc)
  <li>   Hardware/software trade-offs with ASICs, FPGA's, DSPs, general-purpose processors, microcontrollers, etc as building blocks
  <li>   Retargetable compilers and reconfigurable architectures
</ul>
<p>
Please find more information at this workshop's URL: <a href="http://www.imec.be/odes"> http://www.imec.be/odes</a>

<!--
<p  style="margin-bottom: 72px"></p>
<h3>STMCS - Fourth Workshop on Software Tools for MultiCore Systems (STMCS 2009)</h3>

The drive toward multicore systems is led by technology advances such as increasing chip densities and lower design costs of replicated functionality as compared to increasingly complex high-end microprocessors. Multicore systems are already available from leading vendors, and all technology roadmaps suggest a path toward more and more cores on a chip.
<p>
The goal of this workshop is to provide a forum to discuss the impact of the multicore paradigm on the software stack with emphasis on new workloads, programming models, compilers, runtime systems, and tools for performance and functional debugging.
<p>
The workshop is a half day session and will feature invited talks from leading researchers in the field, as well as presentations selected from the submissions.
<p>
The workshop provides a venue to bring together researchers and practitioners working on enabling technology for multicore systems. Original research contributions or position statements are solicited in areas including but not limited to the following:
<ul>
   <li>  Applications and workloads for multicores
   <li>  Programming models for implicit and explicit parallelism
   <li>  Assisted parallelization
   <li>  Relationship to other parallel computing domains (embedded and HPC)
   <li>  O/S and runtime systems for multicores
   <li>  Multicore virtualization
   <li>  Managing heterogeneity in multicores
   <li>  Performance tuning of parallel workloads
   <li>  Debugging parallel software
</ul>
<p>
Please find more information at this workshop's URL: 
<a href="http://cag.csail.mit.edu/~rabbah/conferences/09/cgo/stmcs/">http://cag.csail.mit.edu/~rabbah/conferences/09/cgo/stmcs/</a>
-->

<p  style="margin-bottom: 72px"></p>
<h3>Open64 Workshop</h3>


We invite you to participate in the Open64 Workshop (associated with CGO 2009) to
take place on Sunday, March 22nd and to present your recent research & development
work using the Open64 compiler infrastructure. Active Open64 researchers & developers
from academia and industry will report their research projects, experimental results, and
development experiences using the Open64 compiler.

<p>
A considerable amount of work has been performed with the Open64 compiler
infrastructure over the last few years, we anticipate hearing a number of significant
research topics and encouraging results at this workshop.

<p>
Topics of discussion will be (but are not limited to) findings and results in
<ul>
  <li>
  <li>  porting Open64 to other languages
  <li>  porting Open64 to new target architectures
  <li>  research in general-purpose code analysis and optimization using Open64
  <li>  research in using Open64 for embedded systems
  <li>  runtime optimization
  <li>  parallelization using Open64
  <li>  notable project in using Open64 for significant applications
  <li>  infrastructure/tool development for Open64
  <li>  research in using Open64 for multi-core (many-core) architecture
</ul>
<p>
The workshop provides a forum for discussion of your findings and experiences with a
broad range of Open64 researchers and developers. It is also the main opportunity for the
participants to exchange their expectations and wishes for future development of Open64.
<p>
Please find more information at this workshop's URL: 
<a href="http://www.capsl.udel.edu/conferences/open64/2009/">http://www.capsl.udel.edu/conferences/open64/2009/</a>



<p  style="margin-bottom: 72px"></p>
<h3 id="EPHAM"> EPHAM - Exploiting Parallelism using GPUs and other Hardware-Assisted Methods </h3>

This workshop will focus on compilation techniques for exploiting
parallelism in emerging massively multi-threaded and multi-core
architectures, with a particular focus on the use of general-purpose
GPU computing techniques to overcome traditional barriers to
parallelization. Recently, GPUs have evolved to address programming of
general purpose computations, especially those exemplified by data
parallel models. This change will have long-term implications for
languages, compilers, and programming models. Development of higher
level programming languages, models and compilers that exploit such
processors will be important. Clearly, the economics and performance
of applications is affected by a transition to general-purpose GPU
computing. This will require new ideas and directions as well as
recasting some older techniques to the new paradigm 
<p>
<b>Program</b>

<table border="0">
<tr><td>8:45am - 9:00am<td>Welcome
<tr><td>9:00am - 10:30am<td>Programming Models
<tr><td>                <td><b>Design and Implementation of a High Level Framework
                               for GPUs</b><br>
                            <i>Michael Wolfe</i>
<tr><td>  <td><b>A MapReduce Framework in Heterogenous GPU Environment</b><br>
<i>Dehao Chen, Chuntao Hong, Wenguang Chen, Haibo Lin, Weimin Zheng</i>
<tr><td>  <td><b>GPU Kernels as Data-Parallel Array Computations in Haskell</b><br>
<i>Sean Lee, Manuel M.T. Chakravarty, Vinod Grover, Gabriele Keller</i>

<tr><td>10:30am - 11:00am<td>Break
<tr><td>11:00am - 12:00 noon<td>Application and Performance Frameworks
<tr><td>   <td><b>Analytical Performance Prediction for Evaluation and Tuning of GPGPU Applications</b><br>
<i>Sara Kaghsorkhi, Wen-mei Hwu</i>
<tr><td>   <td><b>GPU-Accelerated Text Mining</b><br>
<i>Yongpeng Zhang, Frank Mueller, Xiaohui Cui, Thomas Potok </i>
<tr><td>12:00 noon - 12:15pm<td>Wrapup
</table>
<p style="margin-bottom: 32px"></p>

<b>Topics of Interest</b>
<p>
We invite papers in this emerging discipline which include, but are
not limited, to the following areas of interest.
<ul>
  <li> Static and dynamic parallelization for hybrid CPU/GPU systems
  <li> Compiler optimizations for GPU computing
  <li> Language constructs and extensions to enable parallel programming with GPUs
  <li> Run-time techniques to off-load computation to the GPU
  <li> Language, programming model, or compiler techniques for mapping irregular computations to GPUs
  <li> Debugging support for GPU programs
  <li> Performance analysis tools related to GPU computing
  <li> Other hardware-assisted methods for extracting and exploiting parallelism
</ul>
<p>
<b>Important Dates</b>
<p>
Feb. 15th 2009:	 Paper submission deadline <br>
Mar. 8th 2009:	 Notification of acceptance <br>
Mar. 15th 2009:	 Camera-ready version of papers due <br>
Mar. 22nd 2009:	 The workshop <br>
<p>
<b>Workshop Organizers</b>
<p>
Vinod Grover, NVIDIA Corporation<br>
Richard Johnson, NVIDIA Corporation<br>
<p>
<b>Program Committee</b>
<p>
Manuel M T Chakravarty, University of New South Wales<br>
Rudi Eigenman, Purdue University<br>
Anwar Ghuloum, Intel<br>
Naga Govindaraju, Microsoft<br>
Wen-mei Hwu, University of Illinois, Urbana-Champaign<br>
Miriam Leeser, Northeastern University<br>
Dinesh Manocha, University of North Carolina<br>
Shane Ryoo, ZeroSoft<br>
Bratin Saha, Intel<br>
Bixia Zheng, AMD<br>

<p>
<b>Submission Guidelines</b>
<p>
Papers of 6-10 pages may be submitted using any format. The abstract
should clearly state the problem being studied, the methods used, and
the results. If the results are preliminary, the authors should state
their expectation for the final results. To submit, please send a pdf
of your submission to epham2009@nvidia.com Final submissions should
use the standard ACM conference format (two columns with 9 pt Times
Roman font, etc.)






<p  style="margin-bottom: 72px"></p>

<h3 id="TBB">Intel&copy Threading Building Blocks: Programming for Current and Future Multicore Platforms</h3>

<b>Organizer:</b><br>
&nbsp&nbsp&nbsp Michael Voss, Ph.D.<br>
&nbsp&nbsp&nbsp Performance, Analysis and Threading Lab, Intel Corporation
<p>
<b>SUMMARY</b>
<p>


An important key to unlocking the performance potential of current and future multicore 
platforms is to choose a programming model that lets you express concurrency without 
requiring that you explicitly manage it. This half-day tutorial introduces the Intel&copy 
Threading Building Blocks concurrency library, which offers a rich and complete 
approach to expressing parallelism in C++ programs.  
<p>


By using a high-level concurrency platform like Intel&copy Threading Building Blocks (Intel 
TBB), developers express the concurrency in their applications and let the runtime library 
manage the low-level, platform-specific details of implementing and scheduling the 
concurrency on the hardware.  It is these implementation and scheduling details that will 
need to change as architectures change.  By using a concurrency platform instead of 
using a native threading library directly, an application is generally easier to write, is 
more likely to be correct, and will continue to enjoy increased performance as platforms 
evolve.  

<p>
After completing this half-day tutorial, attendees will (1) understand why a concurrency 
library such as TBB is often a better choice than using a native threading library 
directly, (2) have a good understanding of the features and capabilities of the TBB 
library and (3) be positioned to begin using the library for developing their own 
applications.  


<p>
<b>ABOUT THE PRESENTER</b>
<p>

Michael Voss is a Senior Staff Software Engineer in the Intel Performance, Analysis and 
Threading Lab where he is one of the senior developers of the Intel&copy Threading Building 
Blocks library.  His interests include languages and compilers for parallel computing, 
adaptive compilation, and optimization.  He received his Ph.D. from the School of 
Electrical and Computer Engineering at Purdue University in 2001.  He was an assistant 
professor in the Edwards S. Rogers Department of Electrical and Computer Engineering at 
the University of Toronto from 2001 - 2005 and an adjunct Professor from 2005 - 2007.   


<p>
<b>OUTLINE OF TOPICS</b>
<p>

<pre>
    1.  Exploiting Multicore Platforms (15 minutes)
        a.  Increasing core counts is the new free lunch
        b.  Threading to the platform is the wrong way to go
            i.  Achieving portable performance is very difficult
            ii. High potential to introduce bugs
            iii. It does not provide a path forward!
        c.  Concurrency platforms are the key to forward-scaling parallelism
            i.  Intel TBB / Microsoft* Parallel Pattern Library
            ii. the OpenMP API
            iii. Data parallel programming models

    2.  An overview of Intel Threading Building Blocks (15 minutes)
        a.  A generic C++ library
        b.  Available as a commercial and open-source package
        c.  Overview of the basic components available in the library

    3.  Concurrent Containers (30 minutes)
        a.  Introduction to concurrent_map, concurrent_queue and concurrent_vector
        b.  compare / contrast with other approaches
        c.  Provide code examples

    4.  Parallel Algorithms (30 minutes)
        a.  introduction to parallel_for, parallel_reduce, parallel_do and pipeline
        b.  discuss Range concept and Partitioner hint
        c.  compare and contrast with other approaches
        d.  Provide code examples

    ---- Mid-point Break ---

    5.  Tasks and the task scheduler (45 minutes)
        a.  Introduction to work-stealing task schedulers
        b.  How to define tasks using Intel TBB
        c.  Provide code examples

    6.  Exception handling and cancellation support (15 minutes)
        a.  The Intel TBB model exceptions and cancellation
        b.  Provide code examples

    7.  tbb_thread (15 minutes)
        a.  An overview of the thread interface
        b.  When to use task and when to use threads
        c.  Provide code examples

    8.  Wrap-up (15 minutes)
        a.  Future directions for TBB
        b.  How to get TBB
        c.  How to interact with the TBB community

</pre>

<p>
Community WEB page: <a href="http://www.threadingbuildingblocks.org/">http://www.threadingbuildingblocks.org/</a>

<p  style="margin-bottom: 72px"></p>
<h3 id="STM">Tutorial on Software Transactional Memory</h3>

<b>Organizers:</b><br>
&nbsp&nbsp&nbsp Yang Ni, Ph.D.   <br>
&nbsp&nbsp&nbsp Adam Welc, Ph.D. <br>
&nbsp&nbsp&nbsp Programming Systems Lab, Intel Corporation
<p>
<b>SUMMARY</b>
<p>
The advent of multi-core processors in the mainstream computing market is forcing programmers to shift from writing sequential code to building concurrent applications. Today, concurrent programs are typically synchronized using locks. However, it is hard to write correct and scalable programs using locks. Fine-grained locks may not compose and are prone to deadlocks. Coarse-grained locks may not deliver the performance promised by multi-core processors. Recently, Transactional Memory (TM) has been proposed as an alternative to locks for multi-core programming. TM has attracted a lot of attention as a safer, more modular, and more scalable concurrency control mechanism.
<p>
This tutorial will provide a comprehensive overview of transactional memory: description of transactional language extensions and their semantics as well as discussion of important aspects of a software transactional memory (STM) system implementation. We will show how to extend C/C++ with transactional constructs and how these constructs alleviate some of the problems related to programming with locks. We will also present the fundamentals of implementing STM algorithms for C/C++ in the TM runtime, describe how TM support can be elegantly expressed in a form of an application interface and discuss generation of the code by the TM compiler that makes appropriate use of such interface.
<p>
<b>ABOUT THE PRESENTERS</b>
<p>
Yang Ni is a Research Scientist in Intel's Programming Systems Lab. He has been working on programming languages for platforms from mobile devices to chip multi processors. His current research focuses on transactional memory. He is a major contributor to the Intel C/C++ TM compiler. Yang received his Ph.D. in Computer Science from Rutgers University.
<p>
Adam Welc is a Research Scientist in Intel's Programming Systems Lab. His work is in the area of programming language design and implementation, with specific interests in concurrency control, compiler and run-time system optimizations, transactional processing as well as architectural support for programming languages and applications. Adam received the Master of Science in Computer Science from Poznan University of Technology, Poland, in July 1999. He continued his graduate studies at Purdue University, receiving the Master of Science in Computer Science in May 2003, and the Ph.D. in Computer Science in March 2006.
<p>

<p  style="margin-bottom: 72px"></p>
<h3 id="WISH">WISH - Workshop on Infrastructures for Software/Hardware co-design</h3>

A major hindrance to the development 
of co-designed hardware and software systems is the availability of 
fast, accurate, and reliable infrastructures for performance evaluation 
and analysis.  Simultaneously varying both the software and hardware 
components of a system introduces complexities which render traditional 
evaluation methodologies unusable. <br></p>

<p>
Traditional evaluation methodologies 
assume that either the hardware or the software components of a system 
are fixed.  For example, an accepted methodology for evaluating 
the effectiveness of a compiler optimization is to compare the execution 
of two differently compiled binaries on the same hardware.  Likewise, 
an accepted methodology for evaluating microarchitectural hardware changes 
has been to measure relatively short, but representative, samples of 
the same program's execution with multiple configurations of a detailed 
timing simulator. <br></p>

<p>
Nonetheless, the co-design 
of hardware and software systems is being pursued as part of many industry 
and academic projects.  Researchers have therefore been forced 
to build their own custom infrastructures and invent methodologies to 
demonstrate the viability of their ideas. The purpose of this workshop 
is for experienced practitioners in this area to share their gained 
expertise and knowledge to a wider audience in the hopes of broadening 
community understanding. Identifying readily-available building blocks 
and tools, as well as opportunities for further improvements in this 
area are the goals of this workshop. <br></p>

<p>Topics of interest include, 
but are not limited to: <br></p>
<ul>
  <li>Trace-based and 
  simulation-based infrastructures</li>
  <li>FPGA-based prototyping</li>

  <li>Performance analysis 
  tools</li>
  <li>Novel methodologies 
  for evaluating co-designed:</li>
  <ul>
    <li>Virtual execution 
    environments</li>
    <li>Dynamic optimization 
    techniques</li>
    <li>Static compilation 
    techniques</li>

    <li>Graphics systems</li>
    <li>Mobile environments</li>
</ul></ul>
<p><b>Important Dates</b></p>
<ul>
  <li>Feb. 16<sup>th</sup> 
  2009 (midnight PST):     Extended Abstracts Due</li>
  <li>Feb. 27<sup>th</sup> 
  2009:       Notification of Acceptance</li>

  <li>Mar. 15<sup>th</sup> 
  2009 (midnight PST):  Final version of 20 minute presentation due</li>
</ul>
<p><b>Submissions guidelines</b></p>
<p>Authors should submit a 3 page 
double spaced extended abstract by February 16<sup>th</sup>, 2009 to 
<a href="mailto:uma.srinivasan@intel.com" target="_blank">uma.srinivasan@intel.com</a><b>. 
</b>Final submission is a slide set for a 20 minute presentation.</p> 

<p><b>General Chair</b></p>
Uma Srinivasan (Intel)

<p><b>Program Chair</b></p>
Anne Holler (VMware)

<p><b>Program Committee</b> <br>

</p>
Jim Callister, Intel<br>
Robert HUndt, Google<br>
Richard Johnson, NVIDIA Corporation<br>
Naveen Neelakantam, University of Illinois, Urbana-Champaign<br>
Uma Srinivasan, Intel<br>
Pratap Subrahmanyam, VMware<br>
Craig Zilles, University of Illinois, Urbana-Champaign<br>
</p>

<p><b>Program</b></p>
Schedule for Workshop on Infrastructures for Software/Hardware co-design (WISH)
 Sunday, 22 March 2009, Afternoon, Room 4
<table border="0">
<tr><td> 1:30-2:30 <td> <b>Keynote</b><br>David R. Ditzel
<tr><td> 2:30-3:00 <td> <b>"Dynamic Binary Translation from 32-bit to 64-bit
          mode for x86 Virtualization"</b><br>Yu-Hsin Joyce Chen 
<tr><td> 3:00-3:30 <td>Break
<tr><td> 3:30-4:00 <td> <b>"Run-time Data Dependence Analysis
          Using Detected Loop Regions in Binary Codes"</b><br>
          Yukinori SATO and Tadao NAKAMURA 
<tr><td> 4:00-4:30 <td> <b>"Cheetah: A Light-Weight,
          Super-Fast Tracing Infrastructure for Itanium Processors"</b><br>
          Ram Srinivasan, Chris Krieger, Jim Callister 
<tr><td> 4:30-5:00 <td> <b>"Simulation-based Performance
          Evaluation of Co-designed Hardware/Software"</b><br>
           Naveen Neelakantam and Craig Zilles 
<tr><td> 5:00-5:30 <td> <b>"Measure of Similarity Degree between
          loops Based on Graph Dependency"</b><br>
          Lamia Djoudi and William Jalby 
</table>
<p  style="margin-bottom: 72px"></p>
<h3 id="SSA"> Tutorial on SSA-based Register Allocation</h3>

<b>Organizers:</b><br>
&nbsp&nbsp&nbsp Philip Brisk, EPFL<br>
&nbsp&nbsp&nbsp Alain Darte, ENS Lyon<br>
&nbsp&nbsp&nbsp Jens Palsberg, UCLA<br>
&nbsp&nbsp&nbsp Fabrice Rastello, ENS Lyon<br>

<p>
<b>SUMMARY</b>
<p>

In the past years, we discovered that the interference graphs of SSA-form programs are chordal. This has several attractive implications for register allocation: First, coloring the interference graph is no longer NP-complete. Second, the number of needed registers is generally less than in non SSA-form programs. Finally, this number is equal to maximal number of simultaneously live variables.

<p>
This opens the door to what we call SSA-based register allocation. The main advantage of this new approach, is that the two problems, spilling, then coloring/coalescing can be optimized separately in two consecutive (more clean and simpler) phases. This is especially interesting for the design of compilers (either aggressive or just in time) for embedded processors.

<p>
The goal of this tutorial is to explain the basics of this in-two-phases approach and to provide the elements to help compiler writers build both memory friendly, fast and competitive (fewer spill code) register allocators. To illustrate this, we will also present new possible approaches to spilling, coalescing, and SSA destruction, as well as experiments with an SSA-based register allocator.

<p>
<b>OUTLINE</b>
<p>
We will start from scratch, explain the key ideas in detail via examples, and present both theoretical and experimental results. We have divided the material such that each speaker will present a well-rounded portion.
<ol>
   <li>Chaitin's et al. NP-completeness theorem, SSA form, polynomial time: Alain Darte
   <li>Spilling, interval graphs, interprocedural: Philip Brisk
   <li>Coalescing: Fabrice Rastello
   <li>SSA destruction, experiments: Jens Palsberg
</ol>

<p>
<b>ABOUT THE PRESENTERS</b>
<p>
Philip Brisk received his B.S., M.S., and Ph.D. degrees, all in Computer Science, from UCLA in 2002, 2003, and 2006 respectively. Since 2006, he has been a postdoctoral scholar with the Ecole Polytechnique Federale de Lausanne (EPFL). His research interests include application-specific processor design, reconfigurable computing, and compilers.

<p>
Alain Darte is a CNRS research scientist at LIP, ENS Lyon, France. He received his Ph.D. degree at ENS-Lyon in 1993. His main scientific interests are in mathematical tools, automatic program transformations, and optimizations for parallelizing compilers and for compiler-based tools used to automatically synthesize hardware accelerators. His main contributions concern polyhedral techniques for loop transformations and memory optimizations, software pipelining, and register allocation, in connexion with industrial partners such as Hewlett Packard (past Pico project) and STMicroelectronics. He is member of the editorial board of ACM TECS and has served in many program committees such as ASAP, CASES, CC, CGO, DATE, Euro-Par, ICS, PLDI.

<p>
Jens Palsberg is a Professor of Computer Science at UCLA. He received a Ph.D. in Computer Science from University of Aarhus, Denmark in 1992. His research interests span the areas of compilers, embedded systems, programming languages, software engineering, and information security. He is an associate editor of ACM Transactions of Programming Languages and Systems, a member of the editorial board of Information and Computation, and a former member of the editorial board of IEEE Transactions on Software Engineering. He is serving as the vice chair of ACM SIGBED, Special Interest Group on Embedded Systems, and he has served as vice chair of computer science at UCLA, as associate head of computer science at Purdue University, as general chair of POPL, as conference chair of LICS, and as a program chair for POPL, EMSOFT, MEMOCODE, PASTE, SAS, SREIS, and TACAS.

<p>
Fabrice Rastello is a researcher of Computer Science at Inria, ENS Lyon, France. He has done his PhD thesis at LIP, ENS Lyon, France (received in 2000) in the field of automatic parallelization (tiling, heterogeneous computing). Then he worked for two years in a compiler group at STMicroelectronics (Grenoble, France) where he mainly developed back-end optimizations in LAO (linear assembly optimizer). His research topic is the compiler optimizations for DSP/VLIW/Media like embedded processors. He still works in collaboration with STmicroelectronics' compiler team for the ST200 family DSP processors. His current research work is focused on JIT compilation, SSA-based optimizations, code compression, register allocation and instruction-cache optimizations. 

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-7012767-1");
pageTracker._trackPageview();
} catch(err) {}</script>
</body>

